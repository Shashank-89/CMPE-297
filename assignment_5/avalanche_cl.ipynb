{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "avalanche_cl.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9_qobwOEkfM",
        "outputId": "36116cd9-107f-4402-9d5e-22de5518642e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/ContinualAI/avalanche.git\n",
            "  Cloning https://github.com/ContinualAI/avalanche.git to /tmp/pip-req-build-if825l_j\n",
            "  Running command git clone -q https://github.com/ContinualAI/avalanche.git /tmp/pip-req-build-if825l_j\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from avalanche-lib==0.0.1) (1.0.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from avalanche-lib==0.0.1) (5.4.8)\n",
            "Collecting pytorchcv\n",
            "  Downloading pytorchcv-0.0.67-py2.py3-none-any.whl (532 kB)\n",
            "\u001b[K     |████████████████████████████████| 532 kB 9.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from avalanche-lib==0.0.1) (0.11.1+cu111)\n",
            "Collecting quadprog\n",
            "  Downloading quadprog-0.1.11.tar.gz (121 kB)\n",
            "\u001b[K     |████████████████████████████████| 121 kB 61.3 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from avalanche-lib==0.0.1) (4.62.3)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from avalanche-lib==0.0.1) (2.7.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from avalanche-lib==0.0.1) (1.10.0+cu111)\n",
            "Collecting gputil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.12.7-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 51.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from avalanche-lib==0.0.1) (1.19.5)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.7/dist-packages (from avalanche-lib==0.0.1) (3.6.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from avalanche-lib==0.0.1) (3.2.2)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from avalanche-lib==0.0.1) (2.0.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from avalanche-lib==0.0.1) (3.10.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from gdown->avalanche-lib==0.0.1) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gdown->avalanche-lib==0.0.1) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->avalanche-lib==0.0.1) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->avalanche-lib==0.0.1) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->avalanche-lib==0.0.1) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->avalanche-lib==0.0.1) (1.3.2)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools->avalanche-lib==0.0.1) (0.29.24)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools->avalanche-lib==0.0.1) (57.4.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gdown->avalanche-lib==0.0.1) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gdown->avalanche-lib==0.0.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gdown->avalanche-lib==0.0.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gdown->avalanche-lib==0.0.1) (2021.10.8)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->avalanche-lib==0.0.1) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->avalanche-lib==0.0.1) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->avalanche-lib==0.0.1) (3.0.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->avalanche-lib==0.0.1) (1.8.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->avalanche-lib==0.0.1) (0.37.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->avalanche-lib==0.0.1) (0.12.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->avalanche-lib==0.0.1) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->avalanche-lib==0.0.1) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->avalanche-lib==0.0.1) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->avalanche-lib==0.0.1) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->avalanche-lib==0.0.1) (0.4.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->avalanche-lib==0.0.1) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->avalanche-lib==0.0.1) (1.42.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->avalanche-lib==0.0.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->avalanche-lib==0.0.1) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->avalanche-lib==0.0.1) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->avalanche-lib==0.0.1) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->avalanche-lib==0.0.1) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->avalanche-lib==0.0.1) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->avalanche-lib==0.0.1) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->avalanche-lib==0.0.1) (3.1.1)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->avalanche-lib==0.0.1) (7.1.2)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb->avalanche-lib==0.0.1) (3.13)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.0-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 57.7 MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 35.8 MB/s \n",
            "\u001b[?25hCollecting configparser>=3.8.1\n",
            "  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb->avalanche-lib==0.0.1) (2.3)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb->avalanche-lib==0.0.1) (7.1.2)\n",
            "Collecting yaspin>=1.0.0\n",
            "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb->avalanche-lib==0.0.1) (1.1.0)\n",
            "Building wheels for collected packages: avalanche-lib, gputil, quadprog, subprocess32, pathtools\n",
            "  Building wheel for avalanche-lib (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for avalanche-lib: filename=avalanche_lib-0.0.1-py3-none-any.whl size=425868 sha256=14c77a62b01ca31908e97d9ecbdff0cec8fb301d1df8ae41960a326408fbd77a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4zfgp40s/wheels/60/fb/ef/c106a98bc821c758882e32e24bb6b3ed11b691715590a071d1\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=2b694b33dfe09fca6322b4ccda9384ab011ce53a65c430d7c47ce10b6fdaa646\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
            "  Building wheel for quadprog (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for quadprog: filename=quadprog-0.1.11-cp37-cp37m-linux_x86_64.whl size=290747 sha256=709be9888cad97a4f8e153a9d0a1760a2ce4eff46c3b0911cab29c7a31be4bf8\n",
            "  Stored in directory: /root/.cache/pip/wheels/4a/4e/d7/41034ea11aeef1266df3cae546116cb6094e955c41ae3e2589\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=0b37eb46d2058c57615621dd43519e4ccda4b7c9cd95478edffd20ecb72a86c9\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=502d45f2f88ad917b44e5170bff9eb2cf35867c3e09d9bb2ad0c999658c9cc39\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built avalanche-lib gputil quadprog subprocess32 pathtools\n",
            "Installing collected packages: smmap, gitdb, yaspin, subprocess32, shortuuid, sentry-sdk, pathtools, GitPython, docker-pycreds, configparser, wandb, quadprog, pytorchcv, gputil, avalanche-lib\n",
            "Successfully installed GitPython-3.1.24 avalanche-lib-0.0.1 configparser-5.2.0 docker-pycreds-0.4.0 gitdb-4.0.9 gputil-1.4.0 pathtools-0.1.2 pytorchcv-0.0.67 quadprog-0.1.11 sentry-sdk-1.5.0 shortuuid-1.0.8 smmap-5.0.0 subprocess32-3.5.4 wandb-0.12.7 yaspin-2.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/ContinualAI/avalanche.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import SGD\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from avalanche.models import SimpleMLP\n",
        "from avalanche.training.strategies import Naive\n",
        "from avalanche.benchmarks.utils import ImageFolder, DatasetFolder, FilelistDataset, AvalancheDataset\n",
        "from avalanche.benchmarks.scenarios.new_classes.nc_scenario import NCScenario\n",
        "from avalanche.benchmarks.classic import SplitOmniglot"
      ],
      "metadata": {
        "id": "qTJK_BD4N3wp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "height = 32\n",
        "n_classes = 964\n",
        "batch_size = 8\n",
        "epochs = 5\n",
        "split_omni = SplitOmniglot(n_experiences=4, \n",
        "                          seed=1, \n",
        "                          train_transform=transforms.Compose([\n",
        "                              transforms.Resize(height),\n",
        "                              transforms.Grayscale(),\n",
        "                              transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.9221,), (0.2681,))\n",
        "                          ]), \n",
        "                          eval_transform=transforms.Compose([\n",
        "                              transforms.Resize(height),\n",
        "                              transforms.Grayscale(),\n",
        "                              transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.9221,), (0.2681,))\n",
        "                          ]))\n",
        "\n",
        "model = SimpleMLP(num_classes=n_classes, input_size=height*height)\n",
        "\n",
        "optimizer = SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "criterion = CrossEntropyLoss()\n",
        "\n",
        "classification = Naive(\n",
        "    model, optimizer, criterion, train_mb_size=batch_size, train_epochs=epochs,\n",
        "    eval_mb_size=batch_size)\n",
        "\n",
        "print('experiment is starting')\n",
        "results = []\n",
        "for exp in split_omni.train_stream:\n",
        "    print(\"Start of experience: \", exp.current_experience)\n",
        "    print(\"Current Classes: \", exp.classes_in_this_experience)\n",
        "\n",
        "    classification.train(exp)\n",
        "    print('completed training')\n",
        "\n",
        "    print('accuracy on complete dataset')\n",
        "    results.append(classification.eval(split_omni.test_stream))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QITD5VmBPnFs",
        "outputId": "86920418-cc51-4ea5-fed8-b1cac701cd59"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "experiment is starting\n",
            "Start of experience:  0\n",
            "Current Classes:  [2, 8, 520, 10, 529, 531, 534, 28, 541, 542, 33, 35, 548, 550, 40, 554, 556, 47, 559, 561, 564, 567, 568, 58, 571, 573, 62, 574, 64, 580, 70, 72, 74, 589, 78, 590, 592, 593, 594, 595, 598, 87, 600, 90, 93, 607, 97, 100, 102, 614, 617, 107, 623, 626, 115, 628, 122, 123, 636, 126, 638, 129, 647, 139, 651, 653, 143, 144, 145, 146, 655, 148, 656, 657, 659, 152, 664, 668, 157, 161, 163, 676, 166, 679, 168, 681, 171, 685, 174, 686, 693, 696, 698, 187, 699, 191, 705, 706, 195, 196, 707, 708, 199, 200, 710, 202, 716, 721, 211, 212, 213, 728, 729, 218, 733, 223, 738, 739, 228, 229, 233, 241, 756, 761, 762, 763, 252, 253, 764, 255, 766, 770, 774, 775, 264, 778, 267, 269, 271, 784, 786, 789, 791, 283, 284, 796, 287, 289, 801, 804, 805, 295, 809, 812, 813, 308, 309, 310, 821, 312, 827, 829, 318, 833, 322, 835, 325, 837, 327, 840, 841, 330, 331, 847, 337, 849, 339, 852, 854, 856, 857, 346, 858, 348, 861, 354, 868, 360, 361, 363, 875, 877, 376, 891, 387, 388, 902, 904, 907, 908, 399, 911, 401, 912, 914, 405, 925, 927, 932, 934, 935, 424, 425, 426, 936, 428, 430, 434, 435, 947, 948, 438, 950, 440, 954, 961, 450, 452, 455, 460, 464, 475, 478, 482, 487, 489, 493, 494, 495, 499, 508]\n",
            "-- >> Start of training phase << --\n",
            "-- Starting training on experience 0 (Task 0) from train stream --\n",
            "100%|██████████| 603/603 [00:17<00:00, 35.39it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 6.2119\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0147\n",
            "100%|██████████| 603/603 [00:07<00:00, 78.19it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.6170\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1075\n",
            "100%|██████████| 603/603 [00:07<00:00, 82.55it/s]\n",
            "Epoch 2 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.5198\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.2481\n",
            "100%|██████████| 603/603 [00:07<00:00, 82.58it/s]\n",
            "Epoch 3 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.8329\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3612\n",
            "100%|██████████| 603/603 [00:07<00:00, 83.24it/s]\n",
            "Epoch 4 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4129\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4369\n",
            "-- >> End of training phase << --\n",
            "completed training\n",
            "accuracy on complete dataset\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 395/395 [00:03<00:00, 113.92it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 7.8684\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0060\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 415/415 [00:03<00:00, 111.51it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 12.2620\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 433/433 [00:03<00:00, 111.66it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 12.3442\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 405/405 [00:03<00:00, 112.01it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 12.3515\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 11.2522\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.0014\n",
            "Start of experience:  1\n",
            "Current Classes:  [0, 512, 514, 3, 515, 5, 6, 516, 518, 523, 527, 17, 18, 20, 533, 22, 24, 538, 27, 539, 29, 540, 545, 549, 551, 552, 41, 553, 44, 557, 48, 50, 563, 54, 59, 579, 68, 584, 585, 76, 588, 80, 86, 92, 604, 605, 606, 609, 98, 101, 613, 615, 106, 108, 109, 621, 625, 116, 118, 637, 128, 640, 641, 134, 135, 138, 654, 660, 153, 667, 156, 160, 673, 162, 164, 165, 677, 167, 680, 170, 682, 172, 684, 175, 687, 177, 689, 180, 181, 182, 183, 692, 694, 695, 697, 188, 193, 714, 203, 205, 207, 208, 720, 722, 214, 726, 730, 220, 732, 735, 224, 225, 736, 740, 230, 742, 745, 234, 749, 753, 242, 754, 757, 758, 247, 248, 759, 760, 251, 256, 768, 771, 261, 779, 268, 780, 270, 781, 275, 276, 787, 790, 281, 799, 800, 291, 293, 807, 296, 808, 300, 814, 818, 820, 824, 313, 319, 320, 321, 832, 323, 834, 836, 338, 344, 862, 863, 864, 353, 355, 356, 869, 874, 367, 882, 883, 884, 373, 374, 887, 888, 378, 381, 894, 383, 897, 386, 898, 900, 901, 903, 392, 393, 394, 395, 396, 906, 910, 400, 402, 404, 916, 407, 409, 923, 413, 929, 930, 422, 427, 940, 429, 432, 436, 437, 441, 955, 956, 445, 446, 963, 454, 457, 458, 466, 469, 470, 471, 474, 476, 477, 479, 483, 484, 485, 490, 491, 500, 501, 504, 507]\n",
            "-- >> Start of training phase << --\n",
            "-- Starting training on experience 1 (Task 0) from train stream --\n",
            "100%|██████████| 603/603 [00:07<00:00, 76.72it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 6.4791\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0187\n",
            "100%|██████████| 603/603 [00:07<00:00, 80.75it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.9800\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1857\n",
            "100%|██████████| 603/603 [00:07<00:00, 81.61it/s]\n",
            "Epoch 2 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.0233\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3278\n",
            "100%|██████████| 603/603 [00:07<00:00, 80.22it/s]\n",
            "Epoch 3 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.5482\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4015\n",
            "100%|██████████| 603/603 [00:07<00:00, 78.27it/s]\n",
            "Epoch 4 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.2235\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4716\n",
            "-- >> End of training phase << --\n",
            "completed training\n",
            "accuracy on complete dataset\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 395/395 [00:03<00:00, 113.10it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 11.9507\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 415/415 [00:03<00:00, 116.04it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 8.4352\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0042\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 433/433 [00:03<00:00, 116.50it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 12.7367\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 405/405 [00:03<00:00, 123.05it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 12.6540\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 11.4444\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.0011\n",
            "Start of experience:  2\n",
            "Current Classes:  [1, 513, 4, 517, 7, 519, 522, 11, 524, 13, 14, 15, 21, 535, 537, 26, 32, 546, 547, 42, 43, 555, 45, 46, 558, 562, 51, 565, 566, 55, 569, 61, 576, 65, 66, 67, 578, 69, 581, 71, 75, 79, 591, 82, 596, 85, 599, 88, 601, 91, 603, 94, 95, 96, 99, 104, 105, 618, 619, 620, 110, 111, 112, 113, 627, 629, 119, 120, 631, 632, 633, 635, 130, 643, 132, 644, 646, 137, 649, 650, 658, 149, 150, 662, 663, 154, 155, 666, 672, 674, 675, 678, 688, 178, 179, 690, 184, 701, 190, 702, 703, 194, 198, 711, 712, 713, 718, 719, 209, 210, 215, 216, 731, 222, 737, 231, 744, 748, 238, 240, 245, 249, 254, 257, 259, 772, 263, 776, 266, 273, 785, 788, 277, 280, 282, 794, 286, 798, 290, 802, 803, 294, 806, 298, 811, 301, 302, 305, 306, 307, 819, 822, 311, 825, 316, 828, 830, 831, 326, 838, 328, 329, 839, 333, 334, 846, 341, 855, 347, 859, 860, 865, 867, 357, 870, 359, 872, 873, 362, 364, 876, 366, 879, 369, 370, 372, 886, 375, 377, 379, 380, 892, 895, 896, 389, 390, 391, 905, 398, 913, 403, 915, 406, 918, 408, 920, 410, 412, 926, 415, 417, 419, 420, 931, 933, 423, 938, 941, 942, 952, 442, 443, 444, 957, 448, 960, 459, 461, 462, 465, 468, 472, 488, 496, 498, 502, 505, 506, 509, 510, 511]\n",
            "-- >> Start of training phase << --\n",
            "-- Starting training on experience 2 (Task 0) from train stream --\n",
            "100%|██████████| 603/603 [00:07<00:00, 83.80it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 6.8788\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0120\n",
            "100%|██████████| 603/603 [00:06<00:00, 86.94it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 3.9476\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1975\n",
            "100%|██████████| 603/603 [00:07<00:00, 85.32it/s]\n",
            "Epoch 2 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.8892\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3359\n",
            "100%|██████████| 603/603 [00:07<00:00, 85.21it/s]\n",
            "Epoch 3 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.3917\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4309\n",
            "100%|██████████| 603/603 [00:07<00:00, 86.05it/s]\n",
            "Epoch 4 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0588\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5044\n",
            "-- >> End of training phase << --\n",
            "completed training\n",
            "accuracy on complete dataset\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 395/395 [00:03<00:00, 114.10it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 12.7174\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 415/415 [00:03<00:00, 115.29it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 12.2996\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 433/433 [00:03<00:00, 116.00it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 8.6584\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0038\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 405/405 [00:03<00:00, 115.47it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 13.1925\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0000\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 11.6634\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.0010\n",
            "Start of experience:  3\n",
            "Current Classes:  [9, 521, 12, 525, 526, 16, 528, 530, 19, 532, 23, 536, 25, 30, 31, 543, 544, 34, 36, 37, 38, 39, 560, 49, 52, 53, 56, 57, 570, 60, 572, 63, 575, 577, 582, 583, 73, 586, 587, 77, 81, 83, 84, 597, 89, 602, 608, 610, 611, 612, 103, 616, 622, 624, 114, 117, 630, 121, 634, 124, 125, 127, 639, 642, 131, 133, 645, 136, 648, 140, 141, 142, 652, 147, 661, 151, 665, 669, 158, 159, 670, 671, 169, 683, 173, 176, 691, 185, 186, 700, 189, 192, 704, 197, 709, 201, 715, 204, 717, 206, 723, 724, 725, 727, 217, 219, 221, 734, 226, 227, 741, 743, 232, 746, 235, 236, 237, 747, 239, 750, 751, 752, 243, 244, 755, 246, 250, 765, 767, 769, 258, 260, 773, 262, 265, 777, 782, 783, 272, 274, 278, 279, 792, 793, 795, 285, 797, 288, 292, 297, 810, 299, 303, 304, 815, 816, 817, 823, 314, 315, 826, 317, 324, 842, 843, 332, 844, 845, 335, 336, 848, 850, 851, 340, 853, 342, 343, 345, 349, 350, 351, 352, 866, 358, 871, 365, 878, 368, 880, 881, 371, 885, 889, 890, 893, 382, 384, 385, 899, 397, 909, 917, 919, 921, 922, 411, 924, 414, 416, 928, 418, 421, 937, 939, 431, 943, 433, 944, 945, 946, 949, 439, 951, 953, 958, 447, 959, 449, 962, 451, 453, 456, 463, 467, 473, 480, 481, 486, 492, 497, 503]\n",
            "-- >> Start of training phase << --\n",
            "-- Starting training on experience 3 (Task 0) from train stream --\n",
            "100%|██████████| 603/603 [00:07<00:00, 84.08it/s]\n",
            "Epoch 0 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 7.1479\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.0100\n",
            "100%|██████████| 603/603 [00:07<00:00, 81.61it/s]\n",
            "Epoch 1 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 4.0958\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.1871\n",
            "100%|██████████| 603/603 [00:07<00:00, 82.12it/s]\n",
            "Epoch 2 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.8882\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.3388\n",
            "100%|██████████| 603/603 [00:07<00:00, 83.61it/s]\n",
            "Epoch 3 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.4010\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4249\n",
            "100%|██████████| 603/603 [00:07<00:00, 85.01it/s]\n",
            "Epoch 4 ended.\n",
            "\tLoss_Epoch/train_phase/train_stream/Task000 = 2.0609\n",
            "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4905\n",
            "-- >> End of training phase << --\n",
            "completed training\n",
            "accuracy on complete dataset\n",
            "-- >> Start of eval phase << --\n",
            "-- Starting eval on experience 0 (Task 0) from test stream --\n",
            "100%|██████████| 395/395 [00:03<00:00, 113.65it/s]\n",
            "> Eval on experience 0 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 12.5098\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.0000\n",
            "-- Starting eval on experience 1 (Task 0) from test stream --\n",
            "100%|██████████| 415/415 [00:03<00:00, 115.88it/s]\n",
            "> Eval on experience 1 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp001 = 12.3809\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp001 = 0.0000\n",
            "-- Starting eval on experience 2 (Task 0) from test stream --\n",
            "100%|██████████| 433/433 [00:03<00:00, 116.99it/s]\n",
            "> Eval on experience 2 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp002 = 11.9732\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp002 = 0.0000\n",
            "-- Starting eval on experience 3 (Task 0) from test stream --\n",
            "100%|██████████| 405/405 [00:03<00:00, 116.73it/s]\n",
            "> Eval on experience 3 (Task 0) from test stream ended.\n",
            "\tLoss_Exp/eval_phase/test_stream/Task000/Exp003 = 8.5585\n",
            "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp003 = 0.0031\n",
            "-- >> End of eval phase << --\n",
            "\tLoss_Stream/eval_phase/test_stream/Task000 = 11.3651\n",
            "\tTop1_Acc_Stream/eval_phase/test_stream/Task000 = 0.0008\n"
          ]
        }
      ]
    }
  ]
}